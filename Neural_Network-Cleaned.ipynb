{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>carat</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>cut_b'Fair'</th>\n",
       "      <th>cut_b'Good'</th>\n",
       "      <th>cut_b'Ideal'</th>\n",
       "      <th>cut_b'Premium'</th>\n",
       "      <th>cut_b'Very Good'</th>\n",
       "      <th>...</th>\n",
       "      <th>color_b'I'</th>\n",
       "      <th>color_b'J'</th>\n",
       "      <th>clarity_b'I1'</th>\n",
       "      <th>clarity_b'IF'</th>\n",
       "      <th>clarity_b'SI1'</th>\n",
       "      <th>clarity_b'SI2'</th>\n",
       "      <th>clarity_b'VS1'</th>\n",
       "      <th>clarity_b'VS2'</th>\n",
       "      <th>clarity_b'VVS1'</th>\n",
       "      <th>clarity_b'VVS2'</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.23</td>\n",
       "      <td>61.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.21</td>\n",
       "      <td>59.8</td>\n",
       "      <td>61.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>56.9</td>\n",
       "      <td>65.0</td>\n",
       "      <td>327.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.29</td>\n",
       "      <td>62.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>334.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.31</td>\n",
       "      <td>63.3</td>\n",
       "      <td>58.0</td>\n",
       "      <td>335.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  carat  depth  table  price  cut_b'Fair'  cut_b'Good'  \\\n",
       "0           0   0.23   61.5   55.0  326.0            0            0   \n",
       "1           1   0.21   59.8   61.0  326.0            0            0   \n",
       "2           2   0.23   56.9   65.0  327.0            0            1   \n",
       "3           3   0.29   62.4   58.0  334.0            0            0   \n",
       "4           4   0.31   63.3   58.0  335.0            0            1   \n",
       "\n",
       "   cut_b'Ideal'  cut_b'Premium'  cut_b'Very Good'  ...  color_b'I'  \\\n",
       "0             1               0                 0  ...           0   \n",
       "1             0               1                 0  ...           0   \n",
       "2             0               0                 0  ...           0   \n",
       "3             0               1                 0  ...           1   \n",
       "4             0               0                 0  ...           0   \n",
       "\n",
       "   color_b'J'  clarity_b'I1'  clarity_b'IF'  clarity_b'SI1'  clarity_b'SI2'  \\\n",
       "0           0              0              0               0               1   \n",
       "1           0              0              0               1               0   \n",
       "2           0              0              0               0               0   \n",
       "3           0              0              0               0               0   \n",
       "4           1              0              0               0               1   \n",
       "\n",
       "   clarity_b'VS1'  clarity_b'VS2'  clarity_b'VVS1'  clarity_b'VVS2'  \n",
       "0               0               0                0                0  \n",
       "1               0               0                0                0  \n",
       "2               1               0                0                0  \n",
       "3               0               1                0                0  \n",
       "4               0               0                0                0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "#  Import and read the charity_data.csv.\n",
    "diamond_df = pd.read_csv(\"./Resources/cleaned.csv\")\n",
    "diamond_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "#try to predict carat\n",
    "\n",
    "y = diamond_df['carat'].values\n",
    "y\n",
    "\n",
    "X = diamond_df.drop('carat', axis=1).values\n",
    "X\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test,y_train,y_test =train_test_split(X,y, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 10)                250       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 15)                165       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                160       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 586\n",
      "Trainable params: 586\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "\n",
    "diamonds_nn= len(X_train_scaled[5])\n",
    "hidden_node_layer = 10\n",
    "second_hidden_node_layer =10\n",
    "third_hidden_layer= 15\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_node_layer, input_dim=diamonds_nn, activation='relu'))\n",
    "#additional layer\n",
    "nn.add(tf.keras.layers.Dense(units=third_hidden_layer, input_dim=diamonds_nn, activation='relu'))\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=second_hidden_node_layer, activation='relu'))\n",
    "\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation='linear'))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "#nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "nn.compile(optimizer='adam',loss='mean_squared_error', metrics=['mean_squared_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "932/932 [==============================] - 5s 4ms/step - loss: 0.0863 - mean_squared_error: 0.0863\n",
      "Epoch 2/10\n",
      "932/932 [==============================] - 4s 5ms/step - loss: 0.0132 - mean_squared_error: 0.0132\n",
      "Epoch 3/10\n",
      "932/932 [==============================] - 2s 3ms/step - loss: 0.0082 - mean_squared_error: 0.0082\n",
      "Epoch 4/10\n",
      "932/932 [==============================] - 4s 4ms/step - loss: 0.0069 - mean_squared_error: 0.0069\n",
      "Epoch 5/10\n",
      "932/932 [==============================] - 5s 5ms/step - loss: 0.0062 - mean_squared_error: 0.0062\n",
      "Epoch 6/10\n",
      "932/932 [==============================] - 4s 4ms/step - loss: 0.0057 - mean_squared_error: 0.0057\n",
      "Epoch 7/10\n",
      "932/932 [==============================] - 4s 4ms/step - loss: 0.0054 - mean_squared_error: 0.0054\n",
      "Epoch 8/10\n",
      "932/932 [==============================] - 3s 4ms/step - loss: 0.0053 - mean_squared_error: 0.0053\n",
      "Epoch 9/10\n",
      "932/932 [==============================] - 2s 3ms/step - loss: 0.0051 - mean_squared_error: 0.0051\n",
      "Epoch 10/10\n",
      "932/932 [==============================] - 2s 3ms/step - loss: 0.0050 - mean_squared_error: 0.0050\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "trained_model = nn.fit(X_train_scaled, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "311/311 - 1s - loss: 0.0045 - mean_squared_error: 0.0045 - 1s/epoch - 4ms/step\n",
      "Loss: 0.004495102446526289, Mean Squared Error: 0.004495102446526289\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Mean Squared Error: {model_accuracy}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = diamond_df['depth'].values\n",
    "y\n",
    "\n",
    "X = diamond_df.drop('depth', axis=1).values\n",
    "X\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test,y_train,y_test =train_test_split(X,y, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 10)                250       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 15)                165       \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 10)                160       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 586\n",
      "Trainable params: 586\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "\n",
    "diamonds_nn= len(X_train_scaled[5])\n",
    "hidden_node_layer = 10\n",
    "second_hidden_node_layer =10\n",
    "third_hidden_layer= 15\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_node_layer, input_dim=diamonds_nn, activation='relu'))\n",
    "#additional layer\n",
    "nn.add(tf.keras.layers.Dense(units=third_hidden_layer, input_dim=diamonds_nn, activation='relu'))\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=second_hidden_node_layer, activation='relu'))\n",
    "\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation='linear'))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "#nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "nn.compile(optimizer='adam',loss='mean_squared_error', metrics=['mean_squared_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "932/932 [==============================] - 3s 3ms/step - loss: 1.9086 - mean_squared_error: 1.9086\n",
      "Epoch 2/10\n",
      "932/932 [==============================] - 4s 5ms/step - loss: 1.9011 - mean_squared_error: 1.9011\n",
      "Epoch 3/10\n",
      "932/932 [==============================] - 3s 4ms/step - loss: 1.8733 - mean_squared_error: 1.8733\n",
      "Epoch 4/10\n",
      "932/932 [==============================] - 3s 3ms/step - loss: 1.8609 - mean_squared_error: 1.8609\n",
      "Epoch 5/10\n",
      "932/932 [==============================] - 4s 4ms/step - loss: 1.8564 - mean_squared_error: 1.8564\n",
      "Epoch 6/10\n",
      "932/932 [==============================] - 4s 4ms/step - loss: 1.8503 - mean_squared_error: 1.8503\n",
      "Epoch 7/10\n",
      "932/932 [==============================] - 4s 4ms/step - loss: 1.8415 - mean_squared_error: 1.8415\n",
      "Epoch 8/10\n",
      "932/932 [==============================] - 4s 4ms/step - loss: 1.8507 - mean_squared_error: 1.8507\n",
      "Epoch 9/10\n",
      "932/932 [==============================] - 4s 4ms/step - loss: 1.8565 - mean_squared_error: 1.8565\n",
      "Epoch 10/10\n",
      "932/932 [==============================] - 4s 4ms/step - loss: 1.8318 - mean_squared_error: 1.8318\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "trained_model = nn.fit(X_train_scaled, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "311/311 - 1s - loss: 1.7537 - mean_squared_error: 1.7537 - 1s/epoch - 4ms/step\n",
      "Loss: 1.7536851167678833, Mean Squared Error: 1.7536851167678833\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Mean Squared Error: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
