{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>cut_b'Fair'</th>\n",
       "      <th>cut_b'Good'</th>\n",
       "      <th>cut_b'Ideal'</th>\n",
       "      <th>cut_b'Premium'</th>\n",
       "      <th>cut_b'Very Good'</th>\n",
       "      <th>color_b'D'</th>\n",
       "      <th>...</th>\n",
       "      <th>color_b'I'</th>\n",
       "      <th>color_b'J'</th>\n",
       "      <th>clarity_b'I1'</th>\n",
       "      <th>clarity_b'IF'</th>\n",
       "      <th>clarity_b'SI1'</th>\n",
       "      <th>clarity_b'SI2'</th>\n",
       "      <th>clarity_b'VS1'</th>\n",
       "      <th>clarity_b'VS2'</th>\n",
       "      <th>clarity_b'VVS1'</th>\n",
       "      <th>clarity_b'VVS2'</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.23</td>\n",
       "      <td>61.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>59.8</td>\n",
       "      <td>61.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.23</td>\n",
       "      <td>56.9</td>\n",
       "      <td>65.0</td>\n",
       "      <td>327.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.29</td>\n",
       "      <td>62.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>334.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.31</td>\n",
       "      <td>63.3</td>\n",
       "      <td>58.0</td>\n",
       "      <td>335.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   carat  depth  table  price  cut_b'Fair'  cut_b'Good'  cut_b'Ideal'  \\\n",
       "0   0.23   61.5   55.0  326.0            0            0             1   \n",
       "1   0.21   59.8   61.0  326.0            0            0             0   \n",
       "2   0.23   56.9   65.0  327.0            0            1             0   \n",
       "3   0.29   62.4   58.0  334.0            0            0             0   \n",
       "4   0.31   63.3   58.0  335.0            0            1             0   \n",
       "\n",
       "   cut_b'Premium'  cut_b'Very Good'  color_b'D'  ...  color_b'I'  color_b'J'  \\\n",
       "0               0                 0           0  ...           0           0   \n",
       "1               1                 0           0  ...           0           0   \n",
       "2               0                 0           0  ...           0           0   \n",
       "3               1                 0           0  ...           1           0   \n",
       "4               0                 0           0  ...           0           1   \n",
       "\n",
       "   clarity_b'I1'  clarity_b'IF'  clarity_b'SI1'  clarity_b'SI2'  \\\n",
       "0              0              0               0               1   \n",
       "1              0              0               1               0   \n",
       "2              0              0               0               0   \n",
       "3              0              0               0               0   \n",
       "4              0              0               0               1   \n",
       "\n",
       "   clarity_b'VS1'  clarity_b'VS2'  clarity_b'VVS1'  clarity_b'VVS2'  \n",
       "0               0               0                0                0  \n",
       "1               0               0                0                0  \n",
       "2               1               0                0                0  \n",
       "3               0               1                0                0  \n",
       "4               0               0                0                0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "#  Import and read the charity_data.csv.\n",
    "diamond_df = pd.read_csv(\"./Resources/cleaned.csv\", index_col=0)\n",
    "diamond_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "#try to predict carat\n",
    "\n",
    "y = diamond_df['carat']\n",
    "\n",
    "\n",
    "X = diamond_df.drop('carat', axis=1)\n",
    "\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test,y_train,y_test =train_test_split(X,y, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61.740280712345296"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The data could be potentially scaled again but there was no need for the scope of the project\n",
    "# Create a StandardScaler instances\n",
    "#scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "#X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "#X_train_scaled = X_scaler.transform(X_train)\n",
    "#X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_68 (Dense)            (None, 10)                240       \n",
      "                                                                 \n",
      " dense_69 (Dense)            (None, 15)                165       \n",
      "                                                                 \n",
      " dense_70 (Dense)            (None, 10)                160       \n",
      "                                                                 \n",
      " dense_71 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 576\n",
      "Trainable params: 576\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "\n",
    "diamonds_nn= len(X_train.columns)\n",
    "hidden_node_layer = 10\n",
    "second_hidden_node_layer = 10\n",
    "third_hidden_layer= 15\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_node_layer, input_dim=diamonds_nn, activation='relu'))\n",
    "#additional layer\n",
    "nn.add(tf.keras.layers.Dense(units=third_hidden_layer, activation='relu'))\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=second_hidden_node_layer, activation='relu'))\n",
    "\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation='linear'))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29817"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "#nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "nn.compile(optimizer='adam',loss='mean_squared_error', metrics=['mean_squared_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "932/932 [==============================] - 7s 4ms/step - loss: 118.7594 - mean_squared_error: 118.7594\n",
      "Epoch 2/20\n",
      "932/932 [==============================] - 5s 5ms/step - loss: 0.0773 - mean_squared_error: 0.0773\n",
      "Epoch 3/20\n",
      "932/932 [==============================] - 5s 5ms/step - loss: 0.0941 - mean_squared_error: 0.0941\n",
      "Epoch 4/20\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 0.2349 - mean_squared_error: 0.2349\n",
      "Epoch 5/20\n",
      "932/932 [==============================] - 5s 5ms/step - loss: 4.7090 - mean_squared_error: 4.7090\n",
      "Epoch 6/20\n",
      "932/932 [==============================] - 5s 5ms/step - loss: 3.0490 - mean_squared_error: 3.0490\n",
      "Epoch 7/20\n",
      "932/932 [==============================] - 5s 5ms/step - loss: 8.9776 - mean_squared_error: 8.9776\n",
      "Epoch 8/20\n",
      "932/932 [==============================] - 5s 5ms/step - loss: 0.4407 - mean_squared_error: 0.4407\n",
      "Epoch 9/20\n",
      "932/932 [==============================] - 6s 6ms/step - loss: 3.1543 - mean_squared_error: 3.1543\n",
      "Epoch 10/20\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 5.5418 - mean_squared_error: 5.5418\n",
      "Epoch 11/20\n",
      "932/932 [==============================] - 5s 5ms/step - loss: 4.2004 - mean_squared_error: 4.2004\n",
      "Epoch 12/20\n",
      "932/932 [==============================] - 5s 5ms/step - loss: 0.6687 - mean_squared_error: 0.6687\n",
      "Epoch 13/20\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 1.2049 - mean_squared_error: 1.2049\n",
      "Epoch 14/20\n",
      "932/932 [==============================] - 15s 16ms/step - loss: 10.0608 - mean_squared_error: 10.0608\n",
      "Epoch 15/20\n",
      "932/932 [==============================] - 7s 8ms/step - loss: 0.5198 - mean_squared_error: 0.5198\n",
      "Epoch 16/20\n",
      "932/932 [==============================] - 6s 7ms/step - loss: 10.2507 - mean_squared_error: 10.2507\n",
      "Epoch 17/20\n",
      "932/932 [==============================] - 7s 7ms/step - loss: 0.0678 - mean_squared_error: 0.0678\n",
      "Epoch 18/20\n",
      "932/932 [==============================] - 9s 10ms/step - loss: 5.5898 - mean_squared_error: 5.5898\n",
      "Epoch 19/20\n",
      "932/932 [==============================] - 7s 7ms/step - loss: 1.2055 - mean_squared_error: 1.2055\n",
      "Epoch 20/20\n",
      "932/932 [==============================] - 4s 4ms/step - loss: 4.6349 - mean_squared_error: 4.6349\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "trained_model = nn.fit(X_train, y_train, epochs=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "311/311 [==============================] - 1s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction = nn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5110655370709956"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "r2_score(y_test, prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "311/311 - 2s - loss: 0.1108 - mean_squared_error: 0.1108 - 2s/epoch - 7ms/step\n",
      "Loss: 0.11079824715852737, Mean Squared Error: 0.11079824715852737\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Mean Squared Error: {model_accuracy}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = diamond_df['depth']\n",
    "y\n",
    "\n",
    "X = diamond_df.drop('depth', axis=1)\n",
    "X\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test,y_train,y_test =train_test_split(X,y, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The data could be potentially scaled again but there was no need for the scope of the project\n",
    "# Create a StandardScaler instances\n",
    "#scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "#X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "#X_train_scaled = X_scaler.transform(X_train)\n",
    "#X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_72 (Dense)            (None, 10)                240       \n",
      "                                                                 \n",
      " dense_73 (Dense)            (None, 15)                165       \n",
      "                                                                 \n",
      " dense_74 (Dense)            (None, 10)                160       \n",
      "                                                                 \n",
      " dense_75 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 576\n",
      "Trainable params: 576\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "\n",
    "diamonds_nn= len(X_train.columns)\n",
    "hidden_node_layer = 10\n",
    "second_hidden_node_layer = 10\n",
    "third_hidden_layer= 15\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_node_layer, input_dim=diamonds_nn, activation='relu'))\n",
    "#additional layer\n",
    "nn.add(tf.keras.layers.Dense(units=third_hidden_layer, activation='relu'))\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=second_hidden_node_layer, activation='relu'))\n",
    "\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation='linear'))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "#nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "nn.compile(optimizer='adam',loss='mean_squared_error', metrics=['mean_squared_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "932/932 [==============================] - 7s 5ms/step - loss: 19771.4180 - mean_squared_error: 19771.4180\n",
      "Epoch 2/20\n",
      "932/932 [==============================] - 4s 4ms/step - loss: 1130.0764 - mean_squared_error: 1130.0764\n",
      "Epoch 3/20\n",
      "932/932 [==============================] - 6s 6ms/step - loss: 543.8096 - mean_squared_error: 543.8096\n",
      "Epoch 4/20\n",
      "932/932 [==============================] - 4s 5ms/step - loss: 89.3230 - mean_squared_error: 89.3230\n",
      "Epoch 5/20\n",
      "932/932 [==============================] - 4s 4ms/step - loss: 13.8476 - mean_squared_error: 13.8476\n",
      "Epoch 6/20\n",
      "932/932 [==============================] - 5s 5ms/step - loss: 11.1866 - mean_squared_error: 11.1866\n",
      "Epoch 7/20\n",
      "932/932 [==============================] - 6s 6ms/step - loss: 10.0647 - mean_squared_error: 10.0647\n",
      "Epoch 8/20\n",
      "932/932 [==============================] - 5s 6ms/step - loss: 10.0941 - mean_squared_error: 10.0941\n",
      "Epoch 9/20\n",
      "932/932 [==============================] - 3s 4ms/step - loss: 10.6983 - mean_squared_error: 10.6983\n",
      "Epoch 10/20\n",
      "932/932 [==============================] - 3s 4ms/step - loss: 11.9295 - mean_squared_error: 11.9295\n",
      "Epoch 11/20\n",
      "932/932 [==============================] - 3s 4ms/step - loss: 11.0255 - mean_squared_error: 11.0255\n",
      "Epoch 12/20\n",
      "932/932 [==============================] - 3s 3ms/step - loss: 11.7657 - mean_squared_error: 11.7657\n",
      "Epoch 13/20\n",
      "932/932 [==============================] - 3s 3ms/step - loss: 11.2890 - mean_squared_error: 11.2890\n",
      "Epoch 14/20\n",
      "932/932 [==============================] - 3s 3ms/step - loss: 13.1272 - mean_squared_error: 13.1272\n",
      "Epoch 15/20\n",
      "932/932 [==============================] - 6s 7ms/step - loss: 11.6158 - mean_squared_error: 11.6158\n",
      "Epoch 16/20\n",
      "932/932 [==============================] - 7s 7ms/step - loss: 11.1624 - mean_squared_error: 11.1624\n",
      "Epoch 17/20\n",
      "932/932 [==============================] - 4s 5ms/step - loss: 10.4675 - mean_squared_error: 10.4675\n",
      "Epoch 18/20\n",
      "932/932 [==============================] - 3s 3ms/step - loss: 10.3280 - mean_squared_error: 10.3280\n",
      "Epoch 19/20\n",
      "932/932 [==============================] - 2s 3ms/step - loss: 10.0862 - mean_squared_error: 10.0862\n",
      "Epoch 20/20\n",
      "932/932 [==============================] - 2s 3ms/step - loss: 10.8677 - mean_squared_error: 10.8677\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "trained_model = nn.fit(X_train, y_train, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "311/311 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction = nn.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.1480489411614885"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "311/311 - 1s - loss: 7.0762 - mean_squared_error: 7.0762 - 704ms/epoch - 2ms/step\n",
      "Loss: 7.076233863830566, Mean Squared Error: 7.076233863830566\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Mean Squared Error: {model_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
